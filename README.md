# Data Cleaning Project

## Overview

This project focuses on cleaning and preprocessing a dataset to make it ready for analysis and visualization. The dataset is processed using Python libraries like Pandas and NumPy to handle missing values, inconsistent formatting, and other data quality issues.


## Dataset

- **File Name**: mini_data_cleaning_project.ipynb
- **Content**: The notebook contains code cells that perform various data cleaning operations.


## Objectives

- Identify and handle missing values.
- Correct inconsistent data formatting.
- Remove duplicate records.
- Standardize data types for analysis.


## Tools & Libraries

- **Python**
- **Pandas**
- **NumPy**
- **Matplotlib / Seaborn** (Optional for visualization)


## Steps Performed

1. **Data Loading**
   - Load the dataset using Pandas.

2. **Initial Exploration**
   - Check the dataset shape, columns, and data types.
   - Identify missing values and duplicates.

3. **Handling Missing Values**
   - Fill or drop missing values based on column relevance.

4. **Data Formatting**
   - Convert columns to appropriate data types (e.g., dates, integers).
   - Standardize text (e.g., lowercase conversion, trimming spaces).

5. **Removing Duplicates**
   - Identify and remove duplicate rows.

6. **Final Dataset Export**
   - Save the cleaned dataset for future analysis.


## How to Use

1. Download and open `mini_data_cleaning_project.ipynb` in Jupyter Notebook or Google Colab.
2. Run each code cell sequentially.
3. Modify file paths as necessary for your local environment.


## Outcome

A cleaned and well-structured dataset ready for analysis and visualization tasks.


## Future Work

- Perform exploratory data analysis (EDA) on the cleaned dataset.
- Build visualizations to uncover insights.
- Apply machine learning models if relevant.


---

## Author 
Siddhart Charan